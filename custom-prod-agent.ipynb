{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce959ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Load product catalog data into a FAISS vector store and save it to directory ############\n",
    "\n",
    "# Load data into data frame\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_path = \"data/t-2.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(df[:2])\n",
    "\n",
    "# Generate a list of Documents\n",
    "documents = []\n",
    "#for index, row in df.iterrows():\n",
    "#    page_content = ' '.join(row[['category-links', 'subcategory-links', 'name']].astype(str))\n",
    "#    metadata = {'index': index}\n",
    "#    document = Document(page_content=page_content, metadata=metadata)\n",
    "#    documents.append(document)\n",
    "\n",
    "data_list = df.to_dict(orient='records')\n",
    "for item in data_list:\n",
    "    page_content = ' '.join([item['category-links'], item['subcategory-links'], item['name']])\n",
    "    metadata = {'index': index}\n",
    "    document = Document(page_content=page_content, metadata=item)\n",
    "    documents.append(document)\n",
    "\n",
    "# The vectorstore we'll be using\n",
    "from langchain.vectorstores import FAISS\n",
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.from_documents(documents, embeddings)\n",
    "found_docs = docsearch.similarity_search('Asus laptop')\n",
    "print(found_docs);\n",
    "docsearch.save_local('t2-embeddings-store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c958d8-6801-4f54-9f23-80075e3d4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Reload the FAISS vector store from previously saved directory ############\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.load_local(folder_path='t2-embeddings-store', embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f8172-e8c2-4405-9235-c119cb169b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def findProds(query) -> str:\n",
    "    data_list = docsearch.similarity_search(query)\n",
    "    # Define a mapping of old keys to new keys (including the NULL mappings)\n",
    "    key_mapping = {\n",
    "        'category-links': 'category',\n",
    "        'subcategory-links' : 'subcategory',\n",
    "        'subcategory-links-href' : 'subcategory-link',\n",
    "        'product-links-href' : 'product-link',\n",
    "        'name' : 'name',\n",
    "        'price' : 'price',\n",
    "        'description' : 'description'\n",
    "    }\n",
    "    updated_items = []\n",
    "    for item in data_list:        \n",
    "        updated_item = {key_mapping.get(key, key): value for key, value in item.metadata.items() if key in key_mapping}\n",
    "        updated_items.append(updated_item)\n",
    "\n",
    "    serialized_data = json.dumps(updated_items)\n",
    "    return serialized_data\n",
    "\n",
    "\n",
    "print(findProds('Asus laptop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4997c-558f-41b5-835e-677d9ce8f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################  define my own tools #################################################\n",
    "from typing import Optional, Type\n",
    "from langchain.tools.base import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "class ProdSearchTool(BaseTool):\n",
    "    name = \"prod_search\"\n",
    "    description = \"\"\"Search product catalog. \n",
    "    Input: product name, category and description, etc. \n",
    "    Output: a list of products in JSon. Each product has the following fields: \n",
    "        category, subcategory, subcategory-link, product-link, name, price, description.\n",
    "        Compose a snippet with product-link as a href for each product to show to customer.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        return \"Tool's final answer: \" + findProds(query)\n",
    "    \n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"ProdSearchTool does not support async\")\n",
    "        \n",
    "        \n",
    "class CustServiceTool(BaseTool):\n",
    "    name = \"customer_service\"\n",
    "    description = \"\"\"General customer service that handles all other than searching product catalog. \n",
    "    Input: customer request.\n",
    "    Output: A web link for redirect customer.\"\"\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        return \"http://www.my-example.com/customer_service/\"\n",
    "    \n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"ProdSearchTool does not support async\")\n",
    "        \n",
    "        \n",
    "tools = [ProdSearchTool(), CustServiceTool()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5391d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"You are a chatbot of a Web store to answer customer questions. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Note that you should give a final answer by formating the json in the Observation if the Observation has a prefix \"Tool's final answer: \".\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[BaseTool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb78493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f10ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d716d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How do I change my account password?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"Do you have any asus laptop?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdd73d-decf-4349-a79e-f2d4ab6f915c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
