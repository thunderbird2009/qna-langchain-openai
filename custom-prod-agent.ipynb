{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce959ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############# Load product catalog data into a FAISS vector store and save it to directory ############\n",
    "\n",
    "# Load data into data frame\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_path = \"data/t-2.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(df[:2])\n",
    "\n",
    "# Generate a list of Documents\n",
    "documents = []\n",
    "#for index, row in df.iterrows():\n",
    "#    page_content = ' '.join(row[['category-links', 'subcategory-links', 'name']].astype(str))\n",
    "#    metadata = {'index': index}\n",
    "#    document = Document(page_content=page_content, metadata=metadata)\n",
    "#    documents.append(document)\n",
    "\n",
    "data_list = df.to_dict(orient='records')\n",
    "for item in data_list:\n",
    "    page_content = ' '.join([item['category-links'], item['subcategory-links'], item['name']])\n",
    "    metadata = {'index': index}\n",
    "    document = Document(page_content=page_content, metadata=item)\n",
    "    documents.append(document)\n",
    "\n",
    "# The vectorstore we'll be using\n",
    "from langchain.vectorstores import FAISS\n",
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.from_documents(documents, embeddings)\n",
    "found_docs = docsearch.similarity_search('Asus laptop')\n",
    "print(found_docs);\n",
    "docsearch.save_local('t2-embeddings-store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03196b0-74fb-49a9-8ffc-7e158b036041",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Load FAQ text data into a FAISS vector store and save it to a directory ############\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "openai_api_key='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'\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'data/CustomerSupportFAQs'\n",
    "docs = []\n",
    "# Traverse the directory and get each file name\n",
    "for filename in os.listdir(directory):\n",
    "    filePath = os.path.join(directory, filename)\n",
    "    if os.path.isfile(filePath):\n",
    "        print(filePath)\n",
    "        loader = TextLoader(filePath)\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "print (f\"{len(docs)} documents with a total {sum([len(x.page_content) for x in docs])} characters\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(docs)\n",
    "print (f\"After split: {len(docs)} documents with a total {sum([len(x.page_content) for x in docs])} characters\")\n",
    "\n",
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.from_documents(docs, embeddings)\n",
    "found_docs = docsearch.similarity_search('How do I request a product return?')\n",
    "print(found_docs);\n",
    "docsearch.save_local('faq-embeddings-store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c958d8-6801-4f54-9f23-80075e3d4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Reload the Product FAISS vector store from previously saved directory ############\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.load_local(folder_path='t2-embeddings-store', embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ba51a-a959-4656-95e0-ec46338c4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Reload the FAQ FAISS vector store from previously saved directory ############\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get your embeddings engine ready\n",
    "faq_embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "faqsearch = FAISS.load_local(folder_path='faq-embeddings-store', embeddings=faq_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c3a10-4940-45db-a336-b0c32f98e2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def findFAQs(query) -> str:\n",
    "    data_list = faqsearch.similarity_search_with_relevance_scores(query, k=1)\n",
    "    if len(data_list) == 0 or data_list[0][1] < 0.5 :\n",
    "        json_data = { 'type' : 'final_msg', 'msg' : 'Have not found an answer from our knowledge base. Will redirect you to an agent.'}\n",
    "        return json.dumps(json_data)\n",
    "    else:\n",
    "        doc = data_list[0][0]\n",
    "        json_data = { 'type' : 'kb_src', 'src' : doc.metadata[\"source\"], 'context': doc.page_content }\n",
    "        return json.dumps(json_data)\n",
    "\n",
    "print(findFAQs('How do I request a product return?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f8172-e8c2-4405-9235-c119cb169b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def findProds(query) -> str:\n",
    "    data_list = docsearch.similarity_search(query)\n",
    "    # Define a mapping of old keys to new keys (including the NULL mappings)\n",
    "    key_mapping = {\n",
    "        'category-links': 'category',\n",
    "        'subcategory-links' : 'subcategory',\n",
    "        'subcategory-links-href' : 'subcategory-link',\n",
    "        'product-links-href' : 'product-link',\n",
    "        'name' : 'name',\n",
    "        'price' : 'price',\n",
    "        'description' : 'description'\n",
    "    }\n",
    "    updated_items = []\n",
    "    for item in data_list:        \n",
    "        updated_item = {key_mapping.get(key, key): value for key, value in item.metadata.items() if key in key_mapping}\n",
    "        updated_items.append(updated_item)\n",
    "\n",
    "    json_data = { 'type' : 'prod_list', 'products' : updated_items}\n",
    "    return json.dumps(json_data)\n",
    "\n",
    "print(findProds('Asus laptop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4997c-558f-41b5-835e-677d9ce8f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################  define my own tools #################################################\n",
    "from typing import Optional, Type\n",
    "from langchain.tools.base import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "class ProdSearchTool(BaseTool):\n",
    "    name = \"prod_search\"\n",
    "    description = \"\"\"Search product catalog. \n",
    "    Input: product name, category and description, etc. \n",
    "    Output: a list of products in JSon. Each product has the following fields: \n",
    "        category, subcategory, subcategory-link, product-link, name, price, description.\n",
    "        Compose a snippet with product-link as a href for each product to show to customer.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        return findProds(query)\n",
    "    \n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"ProdSearchTool does not support async\")\n",
    "        \n",
    "        \n",
    "class CustServiceTool(BaseTool):\n",
    "    name = \"customer_service\"\n",
    "    description = \"\"\"General customer service that handles all other than searching product catalog. \n",
    "    Input: customer request.\n",
    "    Output: A web link for redirect customer.\"\"\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        return findFAQs(query)\n",
    "    \n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"ProdSearchTool does not support async\")\n",
    "        \n",
    "        \n",
    "tools = [ProdSearchTool(), CustServiceTool()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5391d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"You are a chatbot of a Web store to answer customer questions. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Note that you should give a final answer by formating the json or other text in the Observation if the Observation has a prefix \"Tool's final answer: \".\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[BaseTool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb78493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f995595-1242-4624-8722-5e9bd5579f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Any\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "\n",
    "class MyLLMSingleActionAgent(LLMSingleActionAgent):\n",
    "    def plan(\n",
    "        self,\n",
    "        intermediate_steps: List[Tuple[AgentAction, str]],\n",
    "        callbacks: Callbacks = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"\n",
    "        Given input, decided what to do.\n",
    "\n",
    "        Args:\n",
    "            intermediate_steps: Steps the LLM has taken to date,\n",
    "                along with observations\n",
    "            callbacks: Callbacks to run.\n",
    "            **kwargs: User inputs.\n",
    "\n",
    "        Returns:\n",
    "            Action specifying what tool to use.\n",
    "        \"\"\"\n",
    "        if len(intermediate_steps) > 0:\n",
    "            obs = json.loads(intermediate_steps[-1][1])\n",
    "            if obs['type'] == 'prod_list' :\n",
    "                return AgentFinish(\n",
    "                    return_values={\"output\": f'I found the following products:\\n{json.dumps(obs[\"products\"])}\\n'}, log=\"\"\n",
    "                )\n",
    "            elif obs['type'] == 'final_msg':\n",
    "                return AgentFinish(return_values={\"output\": obs['msg']}, log=\"\")\n",
    "            elif obs['type'] == 'kb_src' :\n",
    "                intermediate_steps[-1] = [intermediate_steps[-1][0], obs['context']]\n",
    "                output = self.llm_chain.run(\n",
    "                    intermediate_steps=intermediate_steps,\n",
    "                    stop=self.stop,\n",
    "                    callbacks=callbacks,\n",
    "                    **kwargs,\n",
    "                )\n",
    "                output = output + f'\\nsources:\\n{obs[\"src\"]}'\n",
    "                return self.output_parser.parse(output)\n",
    "\n",
    "        output = self.llm_chain.run(\n",
    "            intermediate_steps=intermediate_steps,\n",
    "            stop=self.stop,\n",
    "            callbacks=callbacks,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self.output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f10ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = MyLLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d716d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How do I change my account password?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"Do you have any asus laptop?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdd73d-decf-4349-a79e-f2d4ab6f915c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
